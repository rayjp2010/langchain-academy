{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f9d81f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd1ebed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather of given city\n",
    "    Args:\n",
    "        city: city to get weather for\n",
    "    Returns:\n",
    "        Weather of the city\n",
    "    \"\"\"\n",
    "    return \"Sunny\"\n",
    "\n",
    "tools = [get_weather]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd25eb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_core.messages import AIMessage\n",
    "from langgraph.types import interrupt\n",
    "\n",
    "checkpoint = InMemorySaver()\n",
    "RISKY_TOOLS = [\"get_weather\"]\n",
    "\n",
    "def halt_on_risky_tools(state):\n",
    "    lastmsg = state[\"messages\"][-1]\n",
    "    if isinstance(lastmsg, AIMessage) and getattr(lastmsg, \"tool_calls\", None):\n",
    "        for tc in lastmsg.tool_calls:\n",
    "            if tc.get(\"name\") in RISKY_TOOLS:\n",
    "                feedback = interrupt({\"awaiting\": tc[\"name\"], \"args\": tc.get(\"args\", {})})\n",
    "                print(f\"feedbacl:{feedback}\")\n",
    "    return {}\n",
    "\n",
    "agent = create_react_agent(model=llm, tools=tools, checkpointer=checkpoint, post_model_hook=halt_on_risky_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7da595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_weather', 'arguments': '{\"city\": \"Osaka\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--4e01712b-3b6a-410d-bf50-5d6e4b3d343f-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'Osaka'}, 'id': 'f33c753e-eb61-4047-a484-459e46216240', 'type': 'tool_call'}], usage_metadata={'input_tokens': 68, 'output_tokens': 15, 'total_tokens': 132, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 49}})]}}\n",
      "{'__interrupt__': (Interrupt(value={'awaiting': 'get_weather', 'args': {'city': 'Osaka'}}, id='875cbb0991aa9c350e3036cff05b958e'),)}\n"
     ]
    }
   ],
   "source": [
    "from langgraph.types import Command\n",
    "\n",
    "for event in agent.stream(Command(resume=True), config={\"thread_id\": 1}):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b880c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
